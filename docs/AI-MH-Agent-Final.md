# AI Mental Health Analysis - Capstone Project

**NTU (SCTP) Advanced Professional Certificate in Data Science & AI**

**Capstone Project: AI Mental Health Support Agent**

---

## Author Information

- **Learner Name:** [Your Full Name]
- **Institution:** National Technological University (NTU)
- **Course:** SCTP Advanced Professional Certificate in Data Science and AI
- **Project Title:** AI Mental Health Support Agent - Multi-Agent RAG System for Youth Mental Health

---

## 1. Project Overview

### Executive Summary

The **AI Mental Health Support Agent** is a multi-agent system built using **LangGraph and Retrieval-Augmented Generation (RAG)** to provide anonymous, accessible mental health support for Singapore youth. This project adapts the capstone's multi-agent architecture to the mental health domain, intelligently routing user inquiries through specialized agents to deliver empathetic, evidence-based responses and appropriate resource recommendations.

Built on research from the Institute of Mental Health's (IMH) National Youth Mental Health Study (NYMHS) showing that **30.6% of Singapore youth experience severe mental health symptoms**, this system demonstrates practical application of advanced AI concepts to address a critical social impact problem.

### Problem Statement

Singapore faces a documented youth mental health crisis with significant barriers to accessing support:

**Statistics (IMH NYMHS 2024):**
- **30.6%** of youth have severe/extremely severe symptoms
- **27%** experience severe anxiety (most common condition)
- **14.9%** suffer from severe depression
- **12.9%** deal with severe stress
- **21%** experience cyberbullying
- **27%** engage in excessive social media use

**Barriers:**
- Stigma and cultural hesitance among young people
- Cost of professional services
- Limited availability and long waiting times
- Lack of awareness about available resources
- Fear of judgment and privacy concerns

There is a critical need for anonymous, accessible, 24/7 preliminary support that can provide empathetic responses, crisis intervention, and appropriate resource recommendations.

### Solution Architecture

This project implements a **domain-agnostic multi-agent system** adapted for mental health support, utilizing:

**Core Technology Stack:**
- **LangGraph:** Multi-agent workflow orchestration
- **RAG (Retrieval-Augmented Generation):** Knowledge-grounded response generation
- **Vector Database:** Chroma for embedding storage and semantic search
- **LLM:** Groq with Llama 3.3 70B (fast, easy)
- **Embedding Model:** HuggingFace all-mpnet-base-v2 (best quality)

**Knowledge Base:**
- Mental health information and coping strategies
- Singapore-specific mental health resources (IMH, CHAT, Samaritans)
- DASS-21 assessment guidelines and severity thresholds
- Crisis intervention protocols and safety procedures
- Evidence-based mental health support content

### Multi-Agent Architecture

The system routes user queries through specialized agents based on semantic classification:

**1. Information Agent**
- **Purpose:** Provides detailed information about mental health topics (depression, anxiety, stress, coping strategies)
- **RAG Integration:** Retrieves relevant mental health information from knowledge base
- **Response Style:** Educational, empathetic, evidence-based
- **Example Queries:** "What is depression?", "How can I manage anxiety?", "Tell me about stress"

**2. Resource Agent** (replaces Policy Agent)
- **Purpose:** Manages inquiries about Singapore mental health resources, services, and helplines
- **RAG Integration:** Retrieves appropriate resources based on severity and user needs
- **Response Content:** IMH services, CHAT centers, Samaritans hotline, school counseling, self-help resources
- **Example Queries:** "Where can I get help?", "What resources are available?", "Who can I talk to?"

**3. Assessment Agent** (replaces Case Agent)
- **Purpose:** Multi-step workflow to guide users through mental health screening using DASS-21 framework
- **Process:** 
  1. Explain DASS-21 assessment
  2. Collect responses to depression questions (7 items)
  3. Collect responses to anxiety questions (7 items)
  4. Collect responses to stress questions (7 items)
  5. Calculate severity scores
  6. Provide appropriate recommendations based on results
- **Example Queries:** "I want to check my mental health", "Can you assess my stress level?", "I need a screening"

**4. Crisis Intervention Agent** (new specialized agent)
- **Purpose:** Immediate response to crisis situations (suicidal ideation, self-harm)
- **Trigger Keywords:** "kill myself", "want to die", "end it all", "hurt myself", "not worth living"
- **Priority:** Highest - bypasses normal routing
- **Response:** Immediate crisis resources (IMH Emergency: 6389-2222, Samaritans: 1767, Emergency: 995)
- **Example Queries:** "I want to end my life", "I can't take this anymore", "I'm going to hurt myself"

**5. Human Escalation Agent**
- **Purpose:** Fallback mechanism for ambiguous queries or explicit requests for human help
- **Trigger Conditions:**
  - Router confidence below threshold (<0.6)
  - User explicitly requests human support
  - Queries outside system scope
- **Response:** Provides information about professional mental health services and encourages seeking human support
- **Example Queries:** "I want to talk to a real person", "Can I speak to a counselor?", ambiguous inputs

### System Workflow

```
User Query Input
    â†“
Router Node (LLM-based semantic classification)
    â†“
    â”œâ”€â”€ Crisis Keywords Detected? â†’ Crisis Intervention Agent â†’ Emergency Resources
    â”œâ”€â”€ Information Request? â†’ Information Agent â†’ RAG Retrieval â†’ Response
    â”œâ”€â”€ Resource Request? â†’ Resource Agent â†’ RAG Retrieval â†’ Singapore Resources
    â”œâ”€â”€ Assessment Request? â†’ Assessment Agent â†’ Multi-step DASS-21 Workflow
    â”œâ”€â”€ Low Confidence? â†’ Human Escalation Agent â†’ Professional Help Info
    â””â”€â”€ Explicit Human Request? â†’ Human Escalation Agent â†’ Professional Help Info
```

### Key Differentiators

**Domain Adaptation:**
- Mental health domain instead of e-commerce
- Specialized crisis intervention agent (safety-critical)
- Multi-step assessment workflow using validated clinical framework (DASS-21)
- Singapore-contextualized resources and services
- Empathetic, trauma-informed response style

**RAG Application:**
- Knowledge base grounded in clinical evidence and local resources
- Semantic retrieval of relevant mental health information
- Context-aware response generation avoiding harmful advice

**Technical Demonstration:**
- LangGraph state management across multi-turn conversations
- Conditional routing based on query intent and risk level
- Vector database construction with domain-specific embeddings
- Integration of LLM for semantic understanding and empathetic response
- Human-in-the-loop design for safety and fallback

---

## 2. Project Deliverables

Your final submission must include:

### 2.1 `ingestion.py` (or `ingestion.ipynb`)

**Purpose:** Process mental health knowledge base files, generate embeddings, and construct vectorized database.

**Functionality:**
- Read all data files from `/data/` directory:
  - `mental_health_info/` (depression, anxiety, stress information)
  - `coping_strategies/` (evidence-based coping techniques)
  - `singapore_resources/` (IMH, CHAT, Samaritans, local services)
  - `dass21_guidelines/` (assessment framework and scoring)
  - `crisis_protocols/` (crisis intervention procedures)
- Split text into appropriately sized chunks (e.g., 500-1000 tokens with 100-token overlap)
- Generate embeddings using chosen embedding model (HuggingFace all-mpnet-base-v2)
- Store embeddings in vector database (Chroma)
- Create separate collections for each knowledge category for targeted retrieval
- Save persistent database to disk

**Expected Output:**
- Vector database directory (e.g., `./chroma_db/`)
- Separate collections: `mental_health_info`, `coping_strategies`, `singapore_resources`, `dass21_guidelines`, `crisis_protocols`
- Log file showing successful ingestion statistics

**Key Functions:**
```python
def load_documents_from_directory(directory_path)
def chunk_documents(documents, chunk_size=500, overlap=100)
def generate_embeddings(chunks, embedding_model)
def create_vector_store(embeddings, chunks, collection_name)
def persist_database(vector_store, output_path)
```

### 2.2 `app.py` (or `app.ipynb`)

**Purpose:** Implement LangGraph multi-agent workflow with state management, agent nodes, routing logic, and RAG integration.

**Core Components:**

**1. State Definition (TypedDict):**
```python
from typing import TypedDict, Annotated, Sequence
from langgraph.graph.message import add_messages

class AgentState(TypedDict):
    messages: Annotated[Sequence[dict], add_messages]
    user_query: str
    next_node: str
    crisis_detected: bool
    assessment_step: int
    assessment_data: dict
    routing_confidence: float
```

**2. Agent Nodes (Functions):**

Each agent implemented as a Python function that:
- Receives current state
- Performs specific task (RAG retrieval, multi-step process, etc.)
- Updates state with response and next routing instruction
- Returns updated state

**Required Nodes:**
```python
def router_node(state: AgentState) -> AgentState
def crisis_intervention_node(state: AgentState) -> AgentState
def information_agent_node(state: AgentState) -> AgentState
def resource_agent_node(state: AgentState) -> AgentState
def assessment_agent_node(state: AgentState) -> AgentState
def human_escalation_node(state: AgentState) -> AgentState
```

**3. Router Node Implementation:**
- Uses LLM to perform semantic classification of user query
- Checks for crisis keywords (highest priority)
- Determines most appropriate agent based on query intent
- Sets `next_node` in state and `routing_confidence` score
- Confidence threshold: route to human escalation if <0.6

**4. RAG Integration:**
- Load persisted vector database collections
- Implement retrieval function with semantic search
- Top-K retrieval (e.g., top 3-5 most relevant chunks)
- Pass retrieved context to LLM for response generation
- Ensure citations/sources are included in responses

**5. Crisis Intervention Logic:**
- Priority keyword detection: ["kill myself", "want to die", "end it all", "hurt myself", "suicide", "not worth living"]
- Immediate routing to crisis agent regardless of other classification
- Response must include emergency hotlines prominently
- No risk of missing crisis queries (zero false negatives acceptable)

**6. Multi-Step Assessment Workflow:**
- State tracking for assessment progress (step 1-22)
- Sequential question asking (7 depression + 7 anxiety + 7 stress + 1 summary)
- Store responses in `assessment_data` state variable
- Calculate DASS-21 severity scores at completion
- Provide risk-appropriate recommendations

**7. Graph Construction:**
```python
from langgraph.graph import StateGraph, END

workflow = StateGraph(AgentState)

# Add nodes
workflow.add_node("router", router_node)
workflow.add_node("crisis_intervention", crisis_intervention_node)
workflow.add_node("information_agent", information_agent_node)
workflow.add_node("resource_agent", resource_agent_node)
workflow.add_node("assessment_agent", assessment_agent_node)
workflow.add_node("human_escalation", human_escalation_node)

# Set entry point
workflow.set_entry_point("router")

# Add conditional edges from router
workflow.add_conditional_edges(
    "router",
    route_to_agent,
    {
        "crisis_intervention": "crisis_intervention",
        "information_agent": "information_agent",
        "resource_agent": "resource_agent",
        "assessment_agent": "assessment_agent",
        "human_escalation": "human_escalation"
    }
)

# Add edges to END
workflow.add_edge("crisis_intervention", END)
workflow.add_edge("information_agent", END)
workflow.add_edge("resource_agent", END)
workflow.add_edge("assessment_agent", END)  # Or back to assessment for multi-turn
workflow.add_edge("human_escalation", END)

# Compile
app = workflow.compile()
```

**8. Testing Interface:**
- Interactive console interface or simple web UI
- Display conversation history
- Show agent routing decisions
- Demonstrate all agent types with test queries

**Expected Output:**
- Fully functional LangGraph application
- Correct routing to appropriate agents
- RAG-based responses with relevant context
- Crisis detection and intervention working
- Multi-step assessment functional
- Human escalation for ambiguous cases

### 2.3 `README.md` (or Markdown cells in Colab notebook)

**Required Sections:**

**Author Information:**
- Learner Name: [Your Full Name]
- Institution: National Technological University (NTU)
- Course: SCTP Advanced Professional Certificate in Data Science and AI
- Project Title: AI Mental Health Support Agent Capstone Project

**Setup and Execution:**
- Python version requirement (3.9+)
- Environment setup (virtual environment)
- Dependency installation (`pip install -r requirements.txt`)
- API key configuration (Groq)
- Step-by-step execution:
  1. Run `ingestion.py` to build knowledge base
  2. Run `app.py` to start the agent system
  3. Test with example queries

**System Architecture:**
- LangGraph workflow diagram (text or visual)
- Explanation of each node's purpose
- Conditional edge logic and routing strategy
- State management approach
- RAG retrieval and response generation flow
- Multi-step assessment workflow details

**Design Rationale:**
- Choice of embedding model (why HuggingFace all-mpnet-base-v2)
- Choice of LLM (why Groq with Llama 3.3 70B)
- Vector database selection (why Chroma)
- Chunking strategy (size and overlap rationale)
- Crisis detection approach and safety considerations
- Domain adaptation from e-commerce to mental health
- Ethical considerations and limitations

**Optional Enhancements (if implemented):**
- Conversation history tracking across sessions
- Sentiment analysis of user inputs
- Confidence scoring for routing decisions
- Multi-language support
- Web interface with Flask/Gradio
- Logging and monitoring

### 2.4 Supporting Files

**Directory Structure:**
```
ai-mental-health-agent/
â”œâ”€â”€ ingestion.py                    # Knowledge base ingestion
â”œâ”€â”€ app.py                          # LangGraph application
â”œâ”€â”€ requirements.txt                # Python dependencies
â”œâ”€â”€ README.md                       # Project documentation
â”œâ”€â”€ .env.example                    # Environment variables template
â”œâ”€â”€ .gitignore                      # Git ignore rules
â”‚
â”œâ”€â”€ data/                           # Knowledge base (raw documents)
â”‚   â”œâ”€â”€ mental_health_info/
â”‚   â”‚   â”œâ”€â”€ depression_info.txt
â”‚   â”‚   â”œâ”€â”€ anxiety_info.txt
â”‚   â”‚   â””â”€â”€ stress_info.txt
â”‚   â”œâ”€â”€ coping_strategies/
â”‚   â”‚   â”œâ”€â”€ breathing_exercises.txt
â”‚   â”‚   â”œâ”€â”€ mindfulness_techniques.txt
â”‚   â”‚   â””â”€â”€ cognitive_strategies.txt
â”‚   â”œâ”€â”€ singapore_resources/
â”‚   â”‚   â”œâ”€â”€ imh_services.txt
â”‚   â”‚   â”œâ”€â”€ chat_services.txt
â”‚   â”‚   â””â”€â”€ community_resources.txt
â”‚   â”œâ”€â”€ dass21_guidelines/
â”‚   â”‚   â””â”€â”€ dass21_framework.txt
â”‚   â””â”€â”€ crisis_protocols/
â”‚       â””â”€â”€ crisis_intervention.txt
â”‚
â”œâ”€â”€ chroma_db/                       # Persisted vector database
â”‚   â”œâ”€â”€ mental_health_info/
â”‚   â”œâ”€â”€ coping_strategies/
â”‚   â”œâ”€â”€ singapore_resources/
â”‚   â”œâ”€â”€ dass21_guidelines/
â”‚   â””â”€â”€ crisis_protocols/
â”‚
â”œâ”€â”€ utils/                          # Helper modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ embeddings.py              # Embedding generation utilities
â”‚   â”œâ”€â”€ retrieval.py               # RAG retrieval functions
â”‚   â””â”€â”€ crisis_detection.py        # Crisis keyword detection
â”‚
â””â”€â”€ tests/                          # Test scripts
    â”œâ”€â”€ test_router.py             # Test routing logic
    â”œâ”€â”€ test_crisis_detection.py   # Test crisis agent
    â”œâ”€â”€ test_rag_retrieval.py      # Test RAG functionality
    â””â”€â”€ test_queries.txt           # Sample test queries
```

**Required Dependencies (`requirements.txt`):**
```
langgraph>=0.0.30
langchain>=0.1.0
langchain-groq>=0.1.0
groq>=0.4.0
chromadb>=0.4.22
sentence-transformers>=2.2.0
python-dotenv>=1.0.0
tiktoken>=0.5.2
numpy>=1.24.0
pandas>=2.1.0
```

---

## 3. Implementation Guidelines

### Step 1: Environment and Knowledge Base Setup

**1.1 Install Dependencies**
```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # Linux/Mac
venv\Scripts\activate     # Windows

# Install packages
pip install --upgrade pip
pip install langgraph langchain langchain-groq groq
pip install chromadb sentence-transformers python-dotenv tiktoken
```

**1.2 Configure API Keys**

Create `.env` file:
```
GROQ_API_KEY=your_groq_api_key_here
```

Load in code:
```python
from dotenv import load_dotenv
import os

load_dotenv()
groq_api_key = os.getenv("GROQ_API_KEY")
```

**1.3 Prepare Knowledge Base**

Create knowledge base files in `/data/` directory:

**Example: `data/mental_health_info/depression_info.txt`**
```
Depression is a common but serious mood disorder that affects how you feel, think, and handle daily activities. According to the IMH National Youth Mental Health Study (NYMHS), 14.9% of Singapore youth experience severe depression.

Symptoms of depression include:
- Persistent sad, anxious, or "empty" mood
- Loss of interest in activities once enjoyed
- Difficulty concentrating or making decisions
- Fatigue and decreased energy
- Feelings of hopelessness or worthlessness
- Changes in sleep patterns (insomnia or oversleeping)
- Changes in appetite or weight

If you experience five or more of these symptoms for more than two weeks, it's important to seek professional help. Depression is treatable with therapy, medication, or a combination of both.
```

**Example: `data/singapore_resources/imh_services.txt`**
```
Institute of Mental Health (IMH) Services for Singapore Youth:

IMH Emergency Department (24/7):
Phone: 6389-2222
Address: 10 Buangkok View, Singapore 539747
Services: Emergency psychiatric care, crisis intervention, immediate assessment

IMH Outpatient Clinic:
Phone: 6389-2000
Operating Hours: Mon-Fri 8am-5:30pm, Sat 8am-1pm
Services: Psychiatric consultation, therapy, medication management
Cost: Subsidized for Singapore residents (means testing available)

CHAT (Community Health Assessment Team):
Phone: 6493-6500
Walk-in: Weekdays 1pm-9pm
Locations: Multiple CHAT centers across Singapore (Jurong, Woodlands, Hougang)
Services: Free mental health check-ups for youth aged 16-30, early intervention, counseling
Cost: FREE
```

### Step 2: Knowledge Base Construction (`ingestion.py`)

**Implementation:**

```python
import os
from typing import List
from langchain.text_splitter import RecursiveCharacterTextSplitter
from sentence_transformers import SentenceTransformer
from langchain_community.vectorstores import Chroma
from langchain.docstore.document import Document
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

def load_documents_from_directory(directory_path: str) -> List[Document]:
    """Load all text files from a directory."""
    documents = []
    
    for filename in os.listdir(directory_path):
        if filename.endswith('.txt'):
            filepath = os.path.join(directory_path, filename)
            with open(filepath, 'r', encoding='utf-8') as f:
                content = f.read()
                documents.append(Document(
                    page_content=content,
                    metadata={"source": filename, "category": os.path.basename(directory_path)}
                ))
    
    return documents

def chunk_documents(documents: List[Document], chunk_size: int = 500, overlap: int = 100) -> List[Document]:
    """Split documents into chunks."""
    text_splitter = RecursiveCharacterTextSplitter(
        chunk_size=chunk_size,
        chunk_overlap=overlap,
        length_function=len,
        separators=["\n\n", "\n", ". ", " ", ""]
    )
    
    chunks = text_splitter.split_documents(documents)
    return chunks

def create_vector_store(chunks: List[Document], collection_name: str, embedding_model) -> Chroma:
    """Create Chroma vector store from document chunks."""
    print(f"Creating vector store for collection: {collection_name}")
    print(f"Number of chunks: {len(chunks)}")
    
    vectorstore = Chroma.from_documents(
        chunks, 
        embedding_model,
        collection_name=collection_name,
        persist_directory=f"./chroma_db/{collection_name}"
    )
    return vectorstore

def persist_database(vectorstore: Chroma, output_path: str):
    """Save vector store to disk."""
    vectorstore.persist()
    print(f"Vector store saved to: {output_path}")

def main():
    """Main ingestion pipeline."""
    print("Starting knowledge base ingestion...")
    
    # Initialize embedding model
    embeddings = SentenceTransformer('all-mpnet-base-v2')
    
    # Define data directories
    data_categories = [
        "mental_health_info",
        "coping_strategies",
        "singapore_resources",
        "dass21_guidelines",
        "crisis_protocols"
    ]
    
    # Process each category
    for category in data_categories:
        print(f"\n{'='*60}")
        print(f"Processing category: {category}")
        print('='*60)
        
        # Load documents
        directory_path = os.path.join("data", category)
        if not os.path.exists(directory_path):
            print(f"Warning: Directory {directory_path} not found. Skipping.")
            continue
        
        documents = load_documents_from_directory(directory_path)
        print(f"Loaded {len(documents)} documents")
        
        # Chunk documents
        chunks = chunk_documents(documents, chunk_size=500, overlap=100)
        print(f"Created {len(chunks)} chunks")
        
        # Create vector store
        vectorstore = create_vector_store(chunks, category, embeddings)
        
        # Persist to disk
        output_path = os.path.join("chroma_db", category)
        os.makedirs(output_path, exist_ok=True)
        persist_database(vectorstore, output_path)
    
    print("\n" + "="*60)
    print("Knowledge base ingestion completed successfully!")
    print("="*60)

if __name__ == "__main__":
    main()
```

**Expected Output:**
```
Starting knowledge base ingestion...

============================================================
Processing category: mental_health_info
============================================================
Loaded 3 documents
Created 15 chunks
Creating vector store for collection: mental_health_info
Number of chunks: 15
Vector store saved to: chroma_db/mental_health_info

...

============================================================
Knowledge base ingestion completed successfully!
============================================================
```

### Step 3: LangGraph Workflow Development (`app.py`)

**3.1 Import Dependencies and Load Vector Stores**

```python
import os
from typing import TypedDict, Annotated, Sequence, Literal
from dotenv import load_dotenv
from langchain_groq import ChatGroq
from sentence_transformers import SentenceTransformer
from langchain_community.vectorstores import Chroma
from langgraph.graph import StateGraph, END
from langgraph.graph.message import add_messages

# Load environment
load_dotenv()

# Initialize LLM
llm = ChatGroq(model="llama-3.3-70b-versatile", temperature=0.7)

# Initialize embeddings
embeddings = SentenceTransformer('all-mpnet-base-v2')

# Load vector stores
vectorstores = {}
categories = ["mental_health_info", "coping_strategies", "singapore_resources", 
              "dass21_guidelines", "crisis_protocols"]

for category in categories:
    path = os.path.join("chroma_db", category)
    if os.path.exists(path):
        vectorstores[category] = Chroma(
            persist_directory=path,
            embedding_function=embeddings,
            collection_name=category
        )
        print(f"Loaded vector store: {category}")
```

**3.2 Define State**

```python
class AgentState(TypedDict):
    """State for the mental health support agent workflow."""
    messages: Annotated[Sequence[dict], add_messages]
    user_query: str
    next_node: str
    crisis_detected: bool
    assessment_step: int
    assessment_data: dict
    routing_confidence: float
    retrieved_context: str
```

**3.3 Implement Crisis Detection**

```python
CRISIS_KEYWORDS = [
    "kill myself", "want to die", "end it all", "commit suicide",
    "hurt myself", "cut myself", "self harm", "not worth living",
    "better off dead", "end my life", "take my own life",
    "no reason to live", "can't go on"
]

def detect_crisis(query: str) -> bool:
    """Check if query contains crisis keywords."""
    query_lower = query.lower()
    for keyword in CRISIS_KEYWORDS:
        if keyword in query_lower:
            return True
    return False
```

**3.4 Implement RAG Retrieval Function**

```python
def retrieve_context(query: str, category: str, k: int = 3) -> str:
    """Retrieve relevant context from vector store."""
    if category not in vectorstores:
        return "No relevant information found."
    
    # Perform similarity search
    docs = vectorstores[category].similarity_search(query, k=k)
    
    # Combine retrieved documents
    context = "\n\n".join([doc.page_content for doc in docs])
    return context
```

**3.5 Implement Router Node**

```python
def router_node(state: AgentState) -> AgentState:
    """Route query to appropriate agent based on semantic classification."""
    query = state["user_query"]
    
    # Priority: Crisis detection
    if detect_crisis(query):
        state["crisis_detected"] = True
        state["next_node"] = "crisis_intervention"
        state["routing_confidence"] = 1.0
        return state
    
    # Use LLM for semantic classification
    classification_prompt = f"""
You are a routing agent for a mental health support system. Classify the following user query into ONE of these categories:

1. information_agent: User wants to learn about mental health topics (depression, anxiety, stress, symptoms, causes)
2. resource_agent: User wants to know about mental health services, helplines, or where to get help in Singapore
3. assessment_agent: User wants to check their mental health, take a screening, or assess their symptoms
4. human_escalation: Query is ambiguous, unclear, or user explicitly requests human help

User Query: "{query}"

Respond ONLY with the category name and a confidence score (0-1) in this format:
Category: [category_name]
Confidence: [score]
"""
    
    response = llm.invoke(classification_prompt)
    response_text = response.content
    
    # Parse response
    category = None
    confidence = 0.5
    
    for line in response_text.split('\n'):
        if line.startswith('Category:'):
            category = line.split(':')[1].strip()
        elif line.startswith('Confidence:'):
            try:
                confidence = float(line.split(':')[1].strip())
            except:
                confidence = 0.5
    
    # Route based on confidence
    if confidence < 0.6:
        state["next_node"] = "human_escalation"
    else:
        state["next_node"] = category
    
    state["routing_confidence"] = confidence
    return state
```

**3.6 Implement Agent Nodes**

```python
def crisis_intervention_node(state: AgentState) -> AgentState:
    """Handle crisis situations with immediate resources."""
    
    response = """
ğŸš¨ **CRISIS SUPPORT AVAILABLE NOW** ğŸš¨

I can hear that you're in a lot of pain right now. Your life matters, and there are people who want to help you immediately.

**Please reach out to these crisis services RIGHT NOW:**

ğŸ“ **IMH Emergency Helpline (24/7)**
   Phone: 6389-2222
   Immediate psychiatric emergency support

ğŸ“ **Samaritans of Singapore (24/7)**
   Phone: 1767
   Confidential emotional support

ğŸ“ **Emergency Services**
   Phone: 995
   For immediate life-threatening situations

You don't have to go through this alone. These trained professionals are ready to support you right now.

If you're not in immediate danger but need support, I'm here to listen. Would you like to talk about what's going on?
"""
    
    state["messages"].append({"role": "assistant", "content": response})
    return state


def information_agent_node(state: AgentState) -> AgentState:
    """Provide mental health information using RAG."""
    query = state["user_query"]
    
    # Retrieve relevant context
    context = retrieve_context(query, "mental_health_info", k=3)
    state["retrieved_context"] = context
    
    # Generate response using LLM + retrieved context
    prompt = f"""
You are a compassionate mental health support agent. Using the following retrieved information, answer the user's question about mental health.

Retrieved Information:
{context}

User Question: {query}

Provide an empathetic, informative response. Include:
1. Clear explanation of the topic
2. Relevant symptoms or signs
3. General coping suggestions
4. Encouragement to seek professional help if needed

Remember: Be supportive and non-judgmental. Do not provide medical diagnoses.

Response:
"""
    
    response = llm.invoke(prompt)
    state["messages"].append({"role": "assistant", "content": response.content})
    return state


def resource_agent_node(state: AgentState) -> AgentState:
    """Provide Singapore mental health resources using RAG."""
    query = state["user_query"]
    
    # Retrieve relevant resources
    context = retrieve_context(query, "singapore_resources", k=4)
    state["retrieved_context"] = context
    
    prompt = f"""
You are a mental health resource agent for Singapore. Using the following information about Singapore mental health services, provide helpful resources to the user.

Available Resources:
{context}

User Request: {query}

Provide a clear, organized response with:
1. Relevant services (name, phone, hours, cost)
2. Brief description of what each service offers
3. Recommendation based on their needs
4. Encouragement to reach out

Format the response with clear sections and bullet points for easy reading.

Response:
"""
    
    response = llm.invoke(prompt)
    state["messages"].append({"role": "assistant", "content": response.content})
    return state


def assessment_agent_node(state: AgentState) -> AgentState:
    """Multi-step DASS-21 assessment workflow."""
    
    # Check if starting new assessment
    if state.get("assessment_step", 0) == 0:
        state["assessment_step"] = 1
        state["assessment_data"] = {}
        
        intro_response = """
I can help you with a mental health screening using the DASS-21 (Depression, Anxiety, and Stress Scale).

This is a brief self-assessment with 21 questions about how you've been feeling recently. It takes about 5 minutes to complete.

**Important:** This is a screening tool, NOT a diagnosis. The results will help you understand your current mental wellbeing and whether you might benefit from professional support.

Would you like to proceed with the assessment? (Yes/No)
"""
        state["messages"].append({"role": "assistant", "content": intro_response})
        return state
    
    # Continue multi-step assessment
    # (Implementation would include all 21 questions, score calculation, and recommendations)
    # For brevity, showing structure:
    
    step = state["assessment_step"]
    
    if step <= 21:
        # Ask next DASS-21 question
        question = get_dass21_question(step)
        state["messages"].append({"role": "assistant", "content": question})
        state["assessment_step"] = step + 1
    else:
        # Calculate scores and provide results
        scores = calculate_dass21_scores(state["assessment_data"])
        recommendations = generate_recommendations(scores)
        state["messages"].append({"role": "assistant", "content": recommendations})
    
    return state


def human_escalation_node(state: AgentState) -> AgentState:
    """Handle ambiguous queries or explicit human help requests."""
    
    response = """
I understand you'd like to speak with a human professional, which is an excellent step.

Here are ways to connect with trained mental health professionals in Singapore:

**For Immediate Support:**
- **CHAT (Community Health Assessment Team)** - Walk-in service for youth
  Phone: 6493-6500
  Hours: Weekdays 1pm-9pm
  Cost: FREE

- **IMH Outpatient Clinic** - Psychiatric consultation
  Phone: 6389-2000
  Hours: Mon-Fri 8am-5:30pm
  Cost: Subsidized for Singapore residents

**School/University Counseling:**
Most educational institutions offer free counseling services. Contact your school's student services office.

**Helplines for Immediate Support:**
- Samaritans of Singapore: 1767 (24/7)
- IMH Emergency: 6389-2222 (24/7)

While waiting to connect with a professional, I'm here to provide information or resources. Is there anything specific I can help you with right now?
"""
    
    state["messages"].append({"role": "assistant", "content": response})
    return state
```

**3.7 Construct and Compile Graph**

```python
def route_to_agent(state: AgentState) -> Literal["crisis_intervention", "information_agent", "resource_agent", "assessment_agent", "human_escalation"]:
    """Conditional routing function."""
    return state["next_node"]

# Build workflow
workflow = StateGraph(AgentState)

# Add nodes
workflow.add_node("router", router_node)
workflow.add_node("crisis_intervention", crisis_intervention_node)
workflow.add_node("information_agent", information_agent_node)
workflow.add_node("resource_agent", resource_agent_node)
workflow.add_node("assessment_agent", assessment_agent_node)
workflow.add_node("human_escalation", human_escalation_node)

# Set entry point
workflow.set_entry_point("router")

# Add conditional edges from router
workflow.add_conditional_edges(
    "router",
    route_to_agent,
    {
        "crisis_intervention": "crisis_intervention",
        "information_agent": "information_agent",
        "resource_agent": "resource_agent",
        "assessment_agent": "assessment_agent",
        "human_escalation": "human_escalation"
    }
)

# Add edges to END
workflow.add_edge("crisis_intervention", END)
workflow.add_edge("information_agent", END)
workflow.add_edge("resource_agent", END)
workflow.add_edge("assessment_agent", END)
workflow.add_edge("human_escalation", END)

# Compile the workflow
app = workflow.compile()
```

**3.8 Testing Interface**

```python
def run_agent():
    """Interactive testing interface."""
    print("\n" + "="*60)
    print("AI MENTAL HEALTH SUPPORT AGENT")
    print("="*60)
    print("Type your query (or 'quit' to exit)\n")
    
    while True:
        user_input = input("You: ").strip()
        
        if user_input.lower() in ['quit', 'exit', 'q']:
            print("\nThank you for using the mental health support agent. Take care!")
            break
        
        if not user_input:
            continue
        
        # Initialize state
        state = {
            "messages": [],
            "user_query": user_input,
            "next_node": "",
            "crisis_detected": False,
            "assessment_step": 0,
            "assessment_data": {},
            "routing_confidence": 0.0,
            "retrieved_context": ""
        }
        
        # Run workflow
        result = app.invoke(state)
        
        # Display response
        if result["messages"]:
            assistant_response = result["messages"][-1]["content"]
            print(f"\nAgent: {assistant_response}\n")
            print(f"[Routed to: {result['next_node']} | Confidence: {result['routing_confidence']:.2f}]\n")
        
        print("-"*60 + "\n")

if __name__ == "__main__":
    run_agent()
```

### Step 4: Testing and Demonstration

**Test Cases to Demonstrate:**

**1. Information Queries:**
```
User: "What is depression?"
Expected: Routes to information_agent, retrieves mental health info, provides educational response

User: "How can I manage anxiety?"
Expected: Routes to information_agent, provides coping strategies from knowledge base
```

**2. Resource Queries:**
```
User: "Where can I get help in Singapore?"
Expected: Routes to resource_agent, provides IMH, CHAT, Samaritans information

User: "Are there free mental health services?"
Expected: Routes to resource_agent, highlights free services like CHAT
```

**3. Assessment Queries:**
```
User: "I want to check my mental health"
Expected: Routes to assessment_agent, starts DASS-21 workflow

User: "Can you assess my stress level?"
Expected: Routes to assessment_agent, begins assessment questions
```

**4. Crisis Queries:**
```
User: "I want to kill myself"
Expected: Immediately routes to crisis_intervention, displays emergency hotlines

User: "I can't take this anymore and want to end it all"
Expected: Crisis detection triggered, emergency resources provided
```

**5. Ambiguous Queries:**
```
User: "I need help"
Expected: May route to human_escalation due to low confidence, provides professional help options

User: "Can I talk to someone?"
Expected: Routes to human_escalation, explains how to connect with professionals
```

---

## 4. Grading Rubric

| **Criterion** | **Weight** | **Evaluation Criteria** |
|---------------|------------|------------------------|
| **Functionality** | **50%** | - System exhibits correct and reliable operation<br>- Accurate query routing to appropriate agents<br>- Effective RAG-based response generation using vector database<br>- Crisis intervention agent properly detects keywords and provides emergency resources<br>- Multi-step assessment agent functional (if implemented)<br>- Human escalation mechanism operational for low-confidence or explicit requests<br>- All agents produce contextually relevant responses<br>- LangGraph workflow executes without errors |
| **Code Quality** | **30%** | - Code is clean, well-structured, and modular<br>- Extensive comments explaining logic<br>- Functions clearly defined with single responsibilities<br>- TypedDict state properly defined and used<br>- Proper error handling throughout<br>- Follows Python best practices (PEP 8)<br>- README provides clear setup and execution instructions<br>- Code is readable and maintainable |
| **Technical Design** | **20%** | - Effective LangGraph architecture with appropriate state management<br>- Appropriate choice of embedding model (OpenAI ada-002 or HuggingFace)<br>- Appropriate choice of LLM (GPT-4, GPT-3.5, or Claude) with clear rationale<br>- Robust retrieval strategy (chunking, k-value, collection organization)<br>- Sound routing strategy with confidence thresholds<br>- Crisis detection logic comprehensive and prioritized<br>- Domain adaptation from e-commerce to mental health well-executed<br>- Any optional enhancements (web UI, sentiment analysis, etc.) contribute to score |

**Detailed Functionality Scoring (50 points):**
- LangGraph workflow executes correctly (10 pts)
- Router classifies queries accurately (10 pts)
- RAG retrieval provides relevant context (8 pts)
- Crisis intervention functional and comprehensive (10 pts - critical safety feature)
- Information and resource agents respond appropriately (6 pts)
- Assessment or human escalation agents functional (6 pts)

**Detailed Code Quality Scoring (30 points):**
- Code structure and modularity (10 pts)
- Comments and documentation (8 pts)
- Error handling and robustness (5 pts)
- README completeness (7 pts)

**Detailed Technical Design Scoring (20 points):**
- LangGraph architecture design (6 pts)
- Model selection and rationale (5 pts)
- RAG strategy effectiveness (5 pts)
- Routing and crisis detection logic (4 pts)

---

## 5. System Architecture

### LangGraph Workflow Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       START (User Query)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     ROUTER NODE                              â”‚
â”‚  - Receives user query                                       â”‚
â”‚  - Priority: Crisis keyword detection                        â”‚
â”‚  - LLM semantic classification                               â”‚
â”‚  - Sets next_node and confidence score                       â”‚
â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚        â”‚         â”‚         â”‚          â”‚
      â”‚ Crisis â”‚ Info    â”‚ Resourceâ”‚ Assess   â”‚ Low Confidence/
      â”‚        â”‚         â”‚         â”‚          â”‚ Explicit Human
      â–¼        â–¼         â–¼         â–¼          â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ CRISIS  â”‚ â”‚  INFO  â”‚ â”‚RESOURCEâ”‚ â”‚ASSESS  â”‚ â”‚   HUMAN      â”‚
â”‚INTERV.  â”‚ â”‚ AGENT  â”‚ â”‚ AGENT  â”‚ â”‚ AGENT  â”‚ â”‚ ESCALATION   â”‚
â”‚         â”‚ â”‚        â”‚ â”‚        â”‚ â”‚        â”‚ â”‚              â”‚
â”‚-Display â”‚ â”‚-RAG    â”‚ â”‚-RAG    â”‚ â”‚-Multi  â”‚ â”‚-Professional â”‚
â”‚ hotlinesâ”‚ â”‚retrieveâ”‚ â”‚retrieveâ”‚ â”‚ step   â”‚ â”‚ help info    â”‚
â”‚-IMH     â”‚ â”‚mental  â”‚ â”‚SG      â”‚ â”‚DASS-21 â”‚ â”‚-Connect      â”‚
â”‚ 6389222 â”‚ â”‚health  â”‚ â”‚resourceâ”‚ â”‚workflowâ”‚ â”‚ resources    â”‚
â”‚-SOS 1767â”‚ â”‚info    â”‚ â”‚        â”‚ â”‚        â”‚ â”‚              â”‚
â”‚-Emerg.  â”‚ â”‚-Generateâ”‚-Generateâ”‚-Calculateâ”‚-Recommend     â”‚
â”‚ 995     â”‚ â”‚responseâ”‚ responseâ”‚ scores  â”‚ human contactâ”‚
â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”¬â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
     â”‚          â”‚          â”‚          â”‚            â”‚
     â”‚          â”‚          â”‚          â”‚            â”‚
     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                         â”‚
                         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         END                                  â”‚
â”‚              (Response returned to user)                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### State Management Flow

```
AgentState (TypedDict):
â”œâ”€â”€ messages: List[dict]           # Conversation history
â”œâ”€â”€ user_query: str                # Current user input
â”œâ”€â”€ next_node: str                 # Routing decision
â”œâ”€â”€ crisis_detected: bool          # Crisis flag
â”œâ”€â”€ assessment_step: int           # Multi-step tracking
â”œâ”€â”€ assessment_data: dict          # DASS-21 responses
â”œâ”€â”€ routing_confidence: float      # Router confidence
â””â”€â”€ retrieved_context: str         # RAG context

State Updates:
1. Router Node: Sets next_node, routing_confidence, crisis_detected
2. Agent Nodes: Append to messages, update retrieved_context
3. Assessment Node: Updates assessment_step, assessment_data
4. END: Final state returned to user
```

### RAG Retrieval Architecture

```
User Query â†’ Router â†’ Agent Node
                         â†“
                   Identify Category
                   (mental_health_info, resources, etc.)
                         â†“
                   Vector Database
                   â”œâ”€â”€ mental_health_info/
                   â”œâ”€â”€ coping_strategies/
                   â”œâ”€â”€ singapore_resources/
                   â”œâ”€â”€ dass21_guidelines/
                   â””â”€â”€ crisis_protocols/
                         â†“
                   Semantic Search (Top-K=3-5)
                         â†“
                   Retrieved Context
                         â†“
                   LLM + Context â†’ Response Generation
                         â†“
                   Return to User
```

### Data Flow Example: Information Query

```
User: "What is depression?"
    â†“
Router Node:
  - No crisis keywords detected
  - LLM classification: "information_agent" (confidence: 0.85)
  - Set next_node = "information_agent"
    â†“
Information Agent Node:
  - Retrieve from vectorstore["mental_health_info"]
  - Semantic search: Top 3 chunks about depression
  - Retrieved Context: [Definition, symptoms, prevalence in Singapore]
    â†“
LLM Response Generation:
  - Prompt: Context + User Query
  - Generate empathetic, informative response
  - Include symptoms, Singapore statistics, encouragement to seek help
    â†“
State Update:
  - Append assistant message
  - Return final state
    â†“
Display to User
```

---

## 6. Design Rationale

### Choice of Embedding Model

**Selected: HuggingFace all-mpnet-base-v2**

**Rationale:**
- **Performance:** State-of-the-art semantic understanding with 768 dimensions, best quality among sentence transformers
- **Cost-Effective:** Free, no API costs, perfect for capstone project
- **Quality:** Superior accuracy in semantic similarity tasks, especially for nuanced language understanding
- **Local Inference:** Runs entirely locally, no API dependencies or rate limits
- **Privacy:** No data sent to external services, important for mental health context

**Alternative Considered:** OpenAI text-embedding-ada-002
- Pros: Good performance, easy API integration
- Cons: Costs money, API dependency, data sent externally
- Decision: HuggingFace chosen for best quality, cost-effectiveness, and privacy

### Choice of LLM

**Selected: Groq with Llama 3.3 70B**

**Rationale:**
- **Speed:** Extremely fast inference (fast, easy), much faster than traditional APIs
- **Cost-Effective:** Competitive pricing, excellent value for performance
- **Quality:** Llama 3.3 70B provides excellent natural language understanding and empathy
- **Context Understanding:** Good context window enables effective RAG integration
- **Safety:** Strong alignment and safety features suitable for mental health domain
- **Reasoning:** Excellent reasoning capabilities for semantic classification and routing

**Alternative Considered:** OpenAI GPT-4
- Pros: Proven performance, excellent empathy
- Cons: Slower, more expensive, API dependency concerns
- Decision: Groq with Llama 3.3 70B chosen for speed, cost-effectiveness, and comparable quality

**Alternative Considered:** Anthropic Claude 3
- Pros: Excellent empathy, strong ethics
- Cons: Higher cost, slower inference
- Decision: Groq chosen for superior speed and cost-effectiveness while maintaining quality

### Vector Database Selection

**Selected: Chroma**

**Rationale:**
- **Performance:** Excellent similarity search performance optimized for embeddings
- **Local:** Runs entirely locally, no external dependencies or services
- **Persistence:** Built-in persistence with automatic database management
- **Ease of Use:** Simple setup and intuitive API for collection management
- **Cost:** Completely free, no API or licensing costs
- **LangChain Integration:** Excellent integration with LangChain ecosystem
- **Metadata Support:** Rich metadata filtering and querying capabilities

**Alternative Considered:** FAISS
- Pros: Very fast similarity search, battle-tested
- Cons: More complex persistence management, less intuitive API
- Decision: Chroma chosen for better persistence, ease of use, and collection management suitable for multi-category knowledge base

### Chunking Strategy

**Selected Parameters:**
- **Chunk Size:** 500 tokens
- **Overlap:** 100 tokens
- **Separator Strategy:** Recursive (\n\n â†’ \n â†’ . â†’ space)

**Rationale:**
- **500 tokens:** Balances context preservation with retrieval granularity
  - Too small (<300): Loses context, increases total chunks
  - Too large (>1000): Reduces retrieval precision, dilutes relevance
- **100-token overlap:** Ensures concepts spanning chunk boundaries aren't lost
- **Recursive splitting:** Preserves natural paragraph and sentence structure for readability

### Crisis Detection Approach

**Design: Keyword-based + Priority Routing**

**Rationale:**
- **Zero False Negatives Required:** Lives depend on catching every crisis query
- **Keyword List Comprehensive:** 13+ variations covering suicidal ideation, self-harm, hopelessness
- **Priority Override:** Crisis detection bypasses normal routing for immediate response
- **LLM Backup:** Router can also identify crisis via semantic understanding
- **Multi-Layer Safety:** Keywords + LLM classification provides redundancy

**Trade-off Accepted:**
- Higher false positive rate acceptable (better safe than sorry)
- Some non-crisis queries may trigger intervention (e.g., "I'm killing time")
- Mitigation: Context-aware response acknowledges potential misunderstanding while still providing resources

### Domain Adaptation: E-Commerce â†’ Mental Health

**Key Adaptations:**

1. **Agent Specialization:**
   - Information Agent: Product info â†’ Mental health education
   - Policy Agent: Company policies â†’ Singapore mental health resources
   - Case Agent: Return process â†’ DASS-21 assessment workflow
   - **New:** Crisis Intervention Agent (safety-critical addition)

2. **Knowledge Base Categories:**
   - Products â†’ Mental health topics (depression, anxiety, stress)
   - Policies â†’ Singapore resources (IMH, CHAT, Samaritans)
   - FAQs â†’ Coping strategies and crisis protocols
   - **New:** DASS-21 guidelines for assessment

3. **Response Style:**
   - Professional business tone â†’ Empathetic, supportive, trauma-informed
   - Problem-solving focus â†’ Emotional validation and resource guidance
   - Efficiency priority â†’ Safety and care priority

4. **Safety Considerations:**
   - Error handling â†’ Crisis detection and intervention
   - Customer satisfaction â†’ User safety and appropriate help-seeking
   - Escalation for complex issues â†’ Escalation for crisis situations

### Ethical Considerations and Limitations

**Ethical Design Choices:**

1. **No Diagnosis:** System explicitly states it does not diagnose, only screens
2. **Professional Referral:** All responses encourage professional help when appropriate
3. **Crisis Priority:** Immediate escalation to human services for high-risk situations
4. **Privacy:** Anonymous system, no data storage beyond session
5. **Transparency:** Clear about AI nature, capabilities, and limitations

**Acknowledged Limitations:**

1. **Not a Replacement:** Cannot replace licensed mental health professionals
2. **Limited Scope:** Pre-defined knowledge base, cannot handle all scenarios
3. **No Emergency Service:** Cannot actively intervene, relies on user action
4. **Cultural Context:** Primarily focused on Singapore context and English language
5. **Technical Limitations:** Subject to LLM hallucinations despite RAG grounding

**Disclaimer Provided:**
"This AI system provides information and support but is NOT a substitute for professional mental health care. If you are in crisis, please contact emergency services or a crisis hotline immediately."

---

## 7. Optional Enhancements (If Implemented)

### Enhancement 1: Web Interface with Flask/Gradio

**Description:** Wrap LangGraph application in web UI for better accessibility

**Implementation:**
```python
import gradio as gr

def chat_interface(user_message, history):
    state = {"user_query": user_message, ...}
    result = app.invoke(state)
    response = result["messages"][-1]["content"]
    return response

demo = gr.ChatInterface(
    fn=chat_interface,
    title="AI Mental Health Support Agent",
    description="Anonymous mental health support powered by AI"
)

demo.launch()
```

**Benefits:**
- More user-friendly than console interface
- Easier demonstration and testing
- Professional presentation

### Enhancement 2: Conversation History Tracking

**Description:** Maintain conversation context across multiple turns

**Implementation:**
- Store conversation history in state
- Reference previous exchanges in subsequent responses
- Track user's emotional trajectory over time

**Benefits:**
- More coherent multi-turn conversations
- Better personalization
- Continuity in assessment workflow

### Enhancement 3: Sentiment Analysis of User Inputs

**Description:** Analyze sentiment of user messages to adjust response tone

**Implementation:**
```python
from textblob import TextBlob

def analyze_sentiment(text):
    blob = TextBlob(text)
    return blob.sentiment.polarity  # -1 to 1

# In agent nodes
sentiment_score = analyze_sentiment(state["user_query"])
if sentiment_score < -0.5:
    # Adjust response for very negative sentiment
```

**Benefits:**
- More empathetic responses calibrated to user's emotional state
- Early warning for declining mental state
- Better crisis detection beyond keywords

### Enhancement 4: Multi-Language Support

**Description:** Support Mandarin, Malay, Tamil for Singapore's multilingual population

**Implementation:**
- Detect input language
- Translate to English for processing
- Translate response back to user's language
- Multilingual knowledge base

**Benefits:**
- Increased accessibility for non-English speakers
- Cultural inclusivity
- Broader impact

### Enhancement 5: Confidence Scoring for Retrieval

**Description:** Score relevance of retrieved documents and adjust response accordingly

**Implementation:**
```python
def retrieve_with_confidence(query, category, threshold=0.7):
    docs_with_scores = vectorstore.similarity_search_with_score(query, k=5)
    filtered_docs = [doc for doc, score in docs_with_scores if score > threshold]
    return filtered_docs
```

**Benefits:**
- Higher quality responses
- Reduced hallucinations
- Better handling of out-of-scope queries

---

## 8. Future Improvements

### Phase 2: Traditional Machine Learning Integration

**Objective:** Add supervised ML models for enhanced risk prediction and classification

**Components to Add:**

**1. Risk Prediction Model**
- **Approach:** Train Random Forest or Gradient Boosting classifier on DASS-21 dataset
- **Features:** Depression/anxiety/stress scores, lifestyle factors (sleep, social media usage, exercise)
- **Target:** Predict risk level (Low/Medium/High) with 75-85% accuracy
- **Integration:** Augment assessment agent with ML prediction alongside DASS-21 scoring
- **Benefit:** More sophisticated risk stratification beyond rule-based thresholds

**2. Intent Classification Model**
- **Approach:** Train Naive Bayes or SVM on labeled mental health queries
- **Features:** TF-IDF or word embeddings of user messages
- **Target:** Classify intent with >85% accuracy
- **Integration:** Replace or augment LLM-based router with trained classifier
- **Benefit:** Faster routing (<100ms), lower API costs, more deterministic

**3. Sentiment Analysis Model**
- **Approach:** Fine-tune DistilBERT or RoBERTa on mental health-specific sentiment data
- **Features:** Text embeddings
- **Target:** Classify sentiment (positive/neutral/negative) with >80% accuracy
- **Integration:** Continuous sentiment tracking throughout conversation
- **Benefit:** Detect emotional deterioration, adjust response empathy

**4. Crisis Detection Model**
- **Approach:** Train binary classifier (Logistic Regression or Neural Network) on crisis vs non-crisis text
- **Features:** Text embeddings + linguistic features (pronouns, negations, severity words)
- **Target:** 100% recall (zero false negatives), precision >50%
- **Integration:** Complement keyword-based detection for robustness
- **Benefit:** Catches crisis expressions not matching exact keywords

**Implementation Steps:**
1. Data collection: Annotate 2,000+ mental health queries (or use existing datasets like CLPsych)
2. Feature engineering: Create TF-IDF vectors, extract linguistic features
3. Model training: Train models with cross-validation
4. Model serialization: Save as .pkl files
5. Integration: Load models in app.py, add prediction functions
6. Evaluation: A/B test against LLM-only baseline

**Example Code Structure:**
```python
# train_models.py
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split
import joblib

# Load DASS-21 dataset
X_train, X_test, y_train, y_test = load_and_split_data()

# Train risk predictor
rf_model = RandomForestClassifier(n_estimators=100)
rf_model.fit(X_train, y_train)
joblib.dump(rf_model, 'models/risk_predictor.pkl')

# In app.py
risk_predictor = joblib.load('models/risk_predictor.pkl')

def predict_risk(features):
    risk_level = risk_predictor.predict([features])[0]
    return risk_level
```

### Phase 3: Advanced NLP with Transformer Fine-Tuning

**Objective:** Fine-tune transformer models on mental health domain

**Components:**

**1. MentalBERT Integration**
- Fine-tune BERT on Reddit Mental Health Corpus
- Use for better semantic understanding of mental health language
- Replace generic embeddings with domain-specific embeddings

**2. Emotion Detection**
- Fine-tune RoBERTa for 7-emotion classification
- Detect anger, joy, sadness, fear, disgust, surprise, optimism
- Track emotional trajectory throughout conversation

**3. Response Generation**
- Fine-tune GPT-2 or LLaMA on curated empathetic mental health responses
- Generate more natural, contextually appropriate responses
- Augment template-based system with generative model

### Phase 4: Multimodal AI

**Objective:** Analyze voice, facial expressions, and writing patterns

**Components:**

**1. Voice Analysis**
- Extract acoustic features (pitch, tone, speech rate)
- Detect emotional state from voice patterns
- Integration with speech-to-text for voice-based interaction

**2. Facial Expression Analysis**
- CNN-based emotion recognition from webcam
- Detect micro-expressions indicative of distress
- Real-time feedback during video counseling

**3. Writing Pattern Analysis**
- Analyze typing speed, deletions, pauses
- Cognitive load indicators
- Hesitation patterns suggesting difficulty expressing thoughts

### Phase 5: Longitudinal Tracking and Predictive Analytics

**Objective:** Track user wellbeing over time and predict deterioration

**Components:**

**1. LSTM Time-Series Models**
- Track DASS-21 scores over multiple assessments
- Predict future risk trajectory
- Early warning system for deteriorating mental health

**2. Relapse Prediction**
- Identify patterns preceding crisis episodes
- Proactive intervention timing
- Personalized risk models per user

**3. Intervention Effectiveness**
- A/B testing different response strategies
- Measure which coping strategies work for which users
- Continuous improvement based on outcomes

### Phase 6: Federated Learning for Privacy-Preserving Improvement

**Objective:** Improve models on real user data without compromising privacy

**Components:**

**1. Federated Model Training**
- Train models locally on user devices
- Aggregate model updates without sharing raw data
- GDPR/PDPA compliant continuous learning

**2. Differential Privacy**
- Add noise to model updates to prevent individual identification
- Balance privacy and model improvement
- Singapore-compliant data handling

---

## 9. Testing and Demonstration

### Test Query Examples

**Test Set 1: Information Queries (Information Agent)**

| Query | Expected Agent | Expected Behavior |
|-------|---------------|-------------------|
| "What is depression?" | information_agent | Retrieve depression info, explain symptoms, prevalence |
| "How can I manage stress?" | information_agent | Provide stress management techniques from knowledge base |
| "Tell me about anxiety symptoms" | information_agent | List anxiety symptoms, explain when to seek help |
| "What causes mental health issues?" | information_agent | Educational response about contributing factors |

**Test Set 2: Resource Queries (Resource Agent)**

| Query | Expected Agent | Expected Behavior |
|-------|---------------|-------------------|
| "Where can I get help in Singapore?" | resource_agent | List IMH, CHAT, Samaritans with contact info |
| "Are there free mental health services?" | resource_agent | Highlight CHAT, Samaritans, subsidized IMH |
| "I want to talk to a counselor" | resource_agent | Provide school counseling, CHAT, IMH outpatient |
| "What helplines are available?" | resource_agent | List all crisis hotlines with 24/7 info |

**Test Set 3: Assessment Queries (Assessment Agent)**

| Query | Expected Agent | Expected Behavior |
|-------|---------------|-------------------|
| "I want to check my mental health" | assessment_agent | Start DASS-21 workflow, explain assessment |
| "Can you assess my depression?" | assessment_agent | Begin DASS-21 with focus on depression subscale |
| "Do a mental health screening" | assessment_agent | Initiate full DASS-21 assessment |

**Test Set 4: Crisis Queries (Crisis Intervention Agent)**

| Query | Expected Agent | Expected Behavior |
|-------|---------------|-------------------|
| "I want to kill myself" | crisis_intervention | Immediate crisis resources, IMH 6389-2222, SOS 1767 |
| "I can't take this anymore and want to end it all" | crisis_intervention | Crisis hotlines, emergency 995, supportive message |
| "I'm going to hurt myself" | crisis_intervention | Self-harm crisis intervention, immediate resources |
| "Life is not worth living" | crisis_intervention | Suicidal ideation response, professional help |

**Test Set 5: Ambiguous Queries (Human Escalation)**

| Query | Expected Agent | Expected Behavior |
|-------|---------------|-------------------|
| "I need help" | human_escalation (low confidence) | Ask for clarification, provide multiple options |
| "Hello" | human_escalation or clarification | Greet, ask what user needs |
| "Thanks" | human_escalation or clarification | Acknowledge, ask if anything else needed |
| "Can I speak to a person?" | human_escalation (explicit) | Explain professional help options |

### Testing Checklist

- [ ] Router correctly classifies all information queries
- [ ] Router correctly classifies all resource queries
- [ ] Router correctly classifies all assessment queries
- [ ] Crisis detection catches ALL crisis keywords (100% recall)
- [ ] RAG retrieval returns relevant context for information queries
- [ ] RAG retrieval returns correct Singapore resources
- [ ] Assessment workflow progresses through all 21 questions
- [ ] Human escalation triggers for ambiguous queries
- [ ] Human escalation triggers for explicit human help requests
- [ ] Confidence scoring works (low confidence â†’ human escalation)
- [ ] Vector stores load successfully at app startup
- [ ] LangGraph executes without errors
- [ ] State updates correctly throughout workflow
- [ ] Responses are empathetic and supportive
- [ ] Responses avoid medical diagnoses
- [ ] Responses encourage professional help appropriately

### Sample Test Run

```bash
$ python app.py

============================================================
AI MENTAL HEALTH SUPPORT AGENT
============================================================
Type your query (or 'quit' to exit)

You: I've been feeling really sad and hopeless lately

Agent: I hear that you're going through a really difficult time right now. Feelings of sadness and hopelessness can be overwhelming, and I want you to know that what you're experiencing is valid.

Based on research from the Institute of Mental Health in Singapore, 14.9% of youth experience severe depression, so you're not alone in this.

Depression often includes symptoms like:
- Persistent sad or "empty" mood
- Loss of interest in activities you used to enjoy
- Difficulty concentrating
- Changes in sleep or appetite
- Feelings of worthlessness or hopelessness

These feelings are serious and deserve attention. I encourage you to consider reaching out to a mental health professional who can provide proper support. Would you like information about mental health services in Singapore?

[Routed to: information_agent | Confidence: 0.87]

------------------------------------------------------------

You: Yes, where can I get help?

Agent: I'm glad you're considering reaching out for support. Here are excellent mental health services available in Singapore:

**For Immediate Support:**
ğŸ“ **CHAT (Community Health Assessment Team)**
   - Phone: 6493-6500
   - Walk-in: Weekdays 1pm-9pm
   - Cost: FREE
   - Service: Mental health check-ups for youth aged 16-30

**For Professional Treatment:**
ğŸ¥ **IMH (Institute of Mental Health) Outpatient Clinic**
   - Phone: 6389-2000
   - Hours: Mon-Fri 8am-5:30pm, Sat 8am-1pm
   - Cost: Subsidized for Singapore residents
   - Service: Psychiatric consultation, therapy, medication management

**24/7 Emotional Support:**
ğŸ“ **Samaritans of Singapore**
   - Phone: 1767
   - Available 24/7
   - Cost: FREE
   - Service: Confidential emotional support

I recommend starting with CHAT for a free assessment, or your school/university counseling service if you're a student. Taking this step shows strength. Would you like more information about any of these services?

[Routed to: resource_agent | Confidence: 0.92]

------------------------------------------------------------

You: quit

Thank you for using the mental health support agent. Take care!
```

---

## 10. Submission Checklist

Before submitting your capstone project, ensure:

**Code Files:**
- [ ] `ingestion.py` or `ingestion.ipynb` - Completes successfully, creates vector database
- [ ] `app.py` or `app.ipynb` - Runs without errors, demonstrates all agents
- [ ] `requirements.txt` - Lists all dependencies with versions
- [ ] `.env.example` - Template for API keys (do NOT include actual keys)

**Documentation:**
- [ ] `README.md` with all required sections:
  - [ ] Author Information (name, institution, course, project title)
  - [ ] Setup and Execution (clear step-by-step instructions)
  - [ ] System Architecture (LangGraph workflow explained)
  - [ ] Design Rationale (model choices justified)
- [ ] Comments throughout code explaining logic
- [ ] Docstrings for all major functions

**Functionality:**
- [ ] Vector database created with separate collections
- [ ] LangGraph workflow compiles and executes
- [ ] Router node classifies queries correctly
- [ ] Crisis intervention agent functional
- [ ] Information agent uses RAG effectively
- [ ] Resource agent retrieves Singapore resources
- [ ] Assessment or human escalation agent functional
- [ ] All test cases pass

**Data:**
- [ ] Knowledge base files in `/data/` directory organized by category
- [ ] Vector database in `/chroma_db/` directory (or documented how to create)
- [ ] Sample test queries documented

**Optional but Recommended:**
- [ ] Web interface (Flask/Gradio) for better demonstration
- [ ] Logging for debugging and monitoring
- [ ] Error handling for missing files, API failures
- [ ] Confidence scoring visualization
- [ ] Conversation history display

---

## 11. Conclusion

This AI Mental Health Support Agent demonstrates the practical application of advanced AI conceptsâ€”specifically **LangGraph multi-agent orchestration and Retrieval-Augmented Generation (RAG)**â€”to address the critical social issue of youth mental health in Singapore.

By adapting the capstone's domain-agnostic architecture to the mental health context, this project showcases:

âœ… **Technical Competency:** LangGraph state management, conditional routing, RAG implementation, vector database construction

âœ… **Domain Adaptation:** Thoughtful translation of e-commerce agents to specialized mental health agents (crisis intervention, assessment, resources)

âœ… **Ethical AI:** Safety-first design with crisis detection, human escalation, clear limitations, and professional referrals

âœ… **Real-World Impact:** Addresses documented problem (30.6% youth with severe symptoms) with culturally appropriate Singapore resources

This project fulfills all capstone requirements while demonstrating that advanced AI techniques can be powerful tools for social good when designed responsibly and deployed thoughtfully.

**Future improvements (Phase 2+)** would integrate traditional machine learning models for risk prediction, intent classification, and sentiment analysisâ€”further enhancing the system's capabilities while maintaining the core LangGraph+RAG architecture established in Phase 1.

---

**Document Version:** 1.0 (Phase 1 - LangGraph + RAG)  
**Date:** October 31, 2025  
**Framework:** LangGraph Multi-Agent System with RAG  
**Future Enhancements:** Traditional ML integration (Phase 2+)

---

## Quick Start Guide

**For Instructors/Reviewers:**

1. **Clone/Download Project**
2. **Install Dependencies:**
   ```bash
   pip install -r requirements.txt
   ```
3. **Set API Key:**
   ```bash
   export GROQ_API_KEY="your_key_here"
   ```
4. **Run Ingestion:**
   ```bash
   python ingestion.py
   ```
   Expected: Vector database created in `/chroma_db/`

5. **Run Application:**
   ```bash
   python app.py
   ```
   Expected: Interactive console interface

6. **Test with Sample Queries:**
   - Crisis: "I want to kill myself"
   - Information: "What is depression?"
   - Resources: "Where can I get help?"
   - Assessment: "Check my mental health"

**Expected Outcomes:**
- Correct routing to appropriate agents
- RAG-based responses with relevant context
- Crisis detection triggers emergency resources
- Human escalation for ambiguous queries

**Grading Focus:**
1. **Functionality (50%):** Does the LangGraph workflow execute correctly? Are responses relevant?
2. **Code Quality (30%):** Is code clean, modular, well-commented?
3. **Technical Design (20%):** Are design choices appropriate and well-justified?

